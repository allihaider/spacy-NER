{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf27013",
   "metadata": {},
   "source": [
    "## Evaluation Criteria\n",
    "* Recall is more important than precision\n",
    "* Current model has R=0.99 and P=0.96 \n",
    "* Change criteria of False Positives and False Negatives as wrong detections with higher or lower than actual priority\n",
    "* Work on POS and Dependency parsing \n",
    "* Add doc site occurence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d242685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from spacy.tokens import DocBin\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ba9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../output_lg/model-best/\"\n",
    "DEV_DATA_PATH = \"../data/dev.spacy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ef4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_entities_equal(ent_1, ent_2):\n",
    "    texts_are_equal = ent_1.text == ent_2.text\n",
    "    start_chars_are_equal = ent_1.start_char == ent_2.start_char\n",
    "    end_chars_are_equal = ent_1.end_char == ent_2.end_char\n",
    "    labels_are_equal = ent_1.label_ == ent_2.label_\n",
    "    \n",
    "    if texts_are_equal and start_chars_are_equal and end_chars_are_equal and labels_are_equal:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830cac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerModel:\n",
    "    def __init__(self, model_path, entity_2_index):\n",
    "        self.model_path = model_path\n",
    "        self.base_model = spacy.load(model_path)\n",
    "        self.vocab = self.base_model.vocab\n",
    "        self.entity_2_index = entity_2_index\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, text):\n",
    "        prediction = self.base_model(text)\n",
    "        predicted_entities = prediction.ents\n",
    "\n",
    "        if len(predicted_entities) != 0:\n",
    "            predicted_entity_indices = [self.entity_2_index[str(entity)] for entity in predicted_entities]\n",
    "            highest_prediction_index = np.argmax(predicted_entity_indices)\n",
    "            predicted_entity = predicted_entities[highest_prediction_index]\n",
    "        else:\n",
    "            predicted_entity = None\n",
    "\n",
    "        return predicted_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a40108",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = spacy.load(MODEL_PATH)\n",
    "\n",
    "db = DocBin()\n",
    "doc_bin = db.from_disk(DEV_DATA_PATH)\n",
    "docs = list(doc_bin.get_docs(original_model.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e73d8",
   "metadata": {},
   "source": [
    "## Create entity ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2398e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = [] \n",
    "\n",
    "for original_doc in docs:\n",
    "    all_entities.append(str(original_doc.ents[0]))\n",
    "    doc_text = original_doc.text\n",
    "    predictions = original_model(doc_text)\n",
    "    predicted_ents = predictions.ents\n",
    "\n",
    "    for ent in predicted_ents:\n",
    "        all_entities.append(str(ent))\n",
    "\n",
    "ordered_entities = np.unique(sorted(all_entities))\n",
    "index_2_entity = dict(enumerate(ordered_entities))\n",
    "entity_2_index = {value:key for key, value in index_2_entity.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581b03d",
   "metadata": {},
   "source": [
    "## Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf5b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = NerModel(MODEL_PATH, entity_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafab230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = []\n",
    "false_prediction_pairs = []\n",
    "\n",
    "for original_doc in docs:\n",
    "    doc_text = original_doc.text\n",
    "    actual_ent = original_doc.ents[0]\n",
    "    predicted_ent = ner_model.predict(doc_text)\n",
    "\n",
    "    if predicted_ent is not None:\n",
    "        entites_are_equal = are_entities_equal(actual_ent, predicted_ent)\n",
    "\n",
    "        if entites_are_equal:\n",
    "            correct_predictions.append(actual_ent)\n",
    "        else:\n",
    "            false_prediction_pairs.append((actual_ent, predicted_ent))\n",
    "    else:\n",
    "        false_prediction_pairs.append((actual_ent, predicted_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0613d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_entities = []\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for prediction_pair in false_prediction_pairs:\n",
    "    actual_ent = prediction_pair[0]\n",
    "    predicted_ent = prediction_pair[1]\n",
    "\n",
    "    if predicted_ent is None:\n",
    "        missed_entities.append(actual_ent) \n",
    "    elif entity_2_index[str(predicted_ent)] > entity_2_index[str(actual_ent)]:\n",
    "        false_positives.append((actual_ent, predicted_ent))\n",
    "    elif entity_2_index[str(predicted_ent)] < entity_2_index[str(actual_ent)]:\n",
    "        false_negatives.append((actual_ent, predicted_ent))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aacde400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples tested: 156\n",
      "Samples predicted correctly: 140\n",
      "Samples predicted incorrectly: 16\n",
      "Missed entities: 9\n",
      "False positives: 3\n",
      "False negatives: 4\n",
      "Accuracy: 89.74%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples tested: {len(docs)}\")\n",
    "print(f\"Samples predicted correctly: {len(correct_predictions)}\")\n",
    "print(f\"Samples predicted incorrectly: {len(false_prediction_pairs)}\")\n",
    "print(f\"Missed entities: {len(missed_entities)}\")\n",
    "print(f\"False positives: {len(false_positives)}\")\n",
    "print(f\"False negatives: {len(false_negatives)}\")\n",
    "print(f\"Accuracy: {100 * (len(correct_predictions)/len(docs)):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
